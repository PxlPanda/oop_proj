import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image

from recognition.crnn_model import CRNN
from recognition.utils_ctc import collate_fn

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
DATASET_DIR = "dataset"
EPOCHS = 50
BATCH_SIZE = 16
NORMALIZE_CASE = False  # üëà False = —Ä–∞–∑–ª–∏—á–∞–µ–º –ê –∏ –∞, True = –≤—Å—ë –≤ –Ω–∏–∂–Ω–∏–π

# === –°–æ–±–∏—Ä–∞–µ–º samples (path, label)

def load_tsv(tsv_path, image_folder):
    samples = []
    if not os.path.exists(tsv_path):
        return samples
    with open(tsv_path, encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("\t")
            if len(parts) != 2:
                print(f"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ (len={len(parts)}): {repr(line)}")
                continue
            filename, label = parts

            if NORMALIZE_CASE:
                label = label.lower()
            img_path = os.path.join(image_folder, filename)
            if os.path.exists(img_path):
                samples.append((img_path, label))
    return samples

samples = []

# --- –ë—É–∫–≤—ã –∏–∑ –ø–∞–ø–æ–∫ –ê/–ë/–í...
for letter_dir in sorted(os.listdir(DATASET_DIR)):
    abs_letter_path = os.path.join(DATASET_DIR, letter_dir)
    if not os.path.isdir(abs_letter_path):
        continue
    if len(letter_dir) != 1 or not letter_dir.isalpha():
        continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫–∏ —Ç–∏–ø–∞ words/, symbols/

    for fname in os.listdir(abs_letter_path):
        if fname.lower().endswith((".jpg", ".png", ".jpeg")):
            label = letter_dir
            if NORMALIZE_CASE:
                label = label.lower()
            samples.append((os.path.join(abs_letter_path, fname), label))

# --- –°–ª–æ–≤–∞ –∏–∑ tsv
samples += load_tsv(os.path.join(DATASET_DIR, "train.tsv"), os.path.join(DATASET_DIR, "train"))
samples += load_tsv(os.path.join(DATASET_DIR, "test.tsv"), os.path.join(DATASET_DIR, "test"))

# === –ê–ª—Ñ–∞–≤–∏—Ç
alphabet = sorted(set(c for _, lbl in samples for c in lbl))
char_to_idx = {c: i for i, c in enumerate(alphabet)}
nclass = len(alphabet) + 1  # blank –¥–ª—è CTC

print(f"–ê–ª—Ñ–∞–≤–∏—Ç: {''.join(alphabet)}")
print(f"–ü—Ä–∏–º–µ—Ä–æ–≤: {len(samples)}")

# === –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
transform = transforms.Compose([
    transforms.Resize((32, 100)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# === Dataset
class OcrDataset(Dataset):
    def __init__(self, samples, transform):
        self.samples = samples
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("L")
        img = self.transform(img)
        return img, label

dataset = OcrDataset(samples, transform)
loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True,
                    collate_fn=lambda b: collate_fn(b, char_to_idx))

# === –ú–æ–¥–µ–ª—å
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = CRNN(32, 1, nclass, 256).to(device)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
weights_dir = "backend/recognition/weights"
weights_path = os.path.join(weights_dir, "crnn_weights.pth")
os.makedirs(weights_dir, exist_ok=True)

if os.path.exists(weights_path):
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    checkpoint = torch.load(weights_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print("–í–µ—Å–∞ –ø–æ–¥–≥—Ä—É–∂–µ–Ω—ã")
else:
    print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è")

criterion = nn.CTCLoss(blank=nclass - 1, zero_infinity=True)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# === –û–±—É—á–µ–Ω–∏–µ
for epoch in range(EPOCHS):
    model.train()
    total_loss = 0
    for images, targets, lengths, labels in loader:
        images = images.to(device)
        targets = targets.to(device)
        preds = model(images)
        preds_log = F.log_softmax(preds, dim=2)
        input_lengths = torch.full((images.size(0),), preds.size(0), dtype=torch.long)
        loss = criterion(preds_log, targets, input_lengths, lengths)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{EPOCHS} ‚Äî Loss: {total_loss:.4f}")

# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
torch.save({'model_state_dict': model.state_dict()}, weights_path)
print("–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:", weights_path)

with open(os.path.join(weights_dir, "alphabet.txt"), "w", encoding="utf-8") as f:
    f.write("".join(alphabet))
print("–ê–ª—Ñ–∞–≤–∏—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
